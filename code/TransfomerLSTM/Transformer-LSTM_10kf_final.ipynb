{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeDataset():\n",
    "    def __init__(self, DATA_PATH):\n",
    "        self.fe(DATA_PATH)\n",
    "        self.user_data = self.k_fold()\n",
    "    \n",
    "    def k_fold(self):\n",
    "        users = self.train_test_df['userID'].unique().tolist() # userID 기준 split\n",
    "        user_data = {}\n",
    "        kf = KFold(n_splits = 5, random_state = 42, shuffle = True) # 8:2 split\n",
    "        for idx, (train_idx, valid_idx) in enumerate(kf.split(users)):\n",
    "            user_data[idx] = valid_idx.tolist()\n",
    "        \n",
    "        return user_data\n",
    "\n",
    "    def fe(self, DATA_PATH):\n",
    "        train_df = pd.read_csv(os.path.join(DATA_PATH, 'train_data.csv'), parse_dates=['Timestamp'])\n",
    "        #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "        train_df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "\n",
    "        test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'), parse_dates=['Timestamp'])\n",
    "        #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "        test_df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "\n",
    "        # 시험지 번호\n",
    "        train_df['assessNum'] = train_df['assessmentItemID'].apply(lambda x:int(x[1:3]))\n",
    "        test_df['assessNum'] = test_df['assessmentItemID'].apply(lambda x:int(x[1:3]))\n",
    "\n",
    "        # 시험지 내 문항번호\n",
    "        train_df['problemNum'] = train_df['assessmentItemID'].apply(lambda x:int(x[3:]))\n",
    "        test_df['problemNum'] = test_df['assessmentItemID'].apply(lambda x:int(x[3:]))\n",
    "\n",
    "        # 문제 푸는데 걸린 시간\n",
    "        def time_diff(df):\n",
    "            df['time'] = df.loc[:, ['userID','Timestamp']].groupby('userID').diff().shift(-1)\n",
    "            df['time'] = df['time'].fillna(df['time'].median())                        # Null값은 중앙값으로 채우기.\n",
    "            df['time'] = df['time'].apply(lambda x:x.total_seconds())                  # 년,월,일,날짜로 되어있는 값을 시간초로 변환\n",
    "            df['time'] = df['time'].apply(lambda x:300 if x > 300 else x)              # 최댓값을 300으로 변환.\n",
    "            df['time'] = df['time']\n",
    "            return df\n",
    "        train_df = time_diff(train_df)\n",
    "        test_df = time_diff(test_df)\n",
    "        \n",
    "        # train data + test data 사용\n",
    "        train_test_df = pd.concat([train_df, test_df])\n",
    "        train_test_df = train_test_df[train_test_df['answerCode'] != -1].reset_index(drop = True)\n",
    "\n",
    "        # 문제를 푼 시간\n",
    "        train_df['hour'] = train_df['Timestamp'].dt.hour\n",
    "        test_df['hour'] = test_df['Timestamp'].dt.hour\n",
    "\n",
    "        # 문제를 푼 요일 # Monday ~ Sunday => 0 ~ 6\n",
    "        train_df['wday'] = train_df['Timestamp'].dt.weekday\n",
    "        test_df['wday'] = test_df['Timestamp'].dt.weekday\n",
    "        \n",
    "        \n",
    "        # index 로 변환\n",
    "        def emb_idx(emb_list) -> dict:\n",
    "            embidx = {}\n",
    "            for idx, i in enumerate(emb_list):\n",
    "                embidx[i] = idx\n",
    "            return embidx\n",
    "\n",
    "        # 범주형 변수 -> embedding 추가\n",
    "        assessmentItemID2idx = emb_idx(train_test_df['assessmentItemID'].unique().tolist())\n",
    "        testId2idx = emb_idx(train_test_df['testId'].unique().tolist())\n",
    "        KnowledgeTag2idx = emb_idx(train_test_df['KnowledgeTag'].unique().tolist())\n",
    "        problemNum2idx = emb_idx(train_test_df['problemNum'].unique().tolist())\n",
    "        assessNum2idx = emb_idx(train_test_df['assessNum'].unique().tolist())\n",
    "\n",
    "        train_df['assessmentItemID2idx'] = train_df['assessmentItemID'].apply(lambda x : assessmentItemID2idx[x])\n",
    "        train_df['testId2idx'] = train_df['testId'].apply(lambda x : testId2idx[x])\n",
    "        train_df['KnowledgeTag2idx'] = train_df['KnowledgeTag'].apply(lambda x : KnowledgeTag2idx[x])\n",
    "        train_df['problemNum2idx'] = train_df['problemNum'].apply(lambda x : problemNum2idx[x])\n",
    "        train_df['assessNum2idx'] = train_df['assessNum'].apply(lambda x : assessNum2idx[x])\n",
    "\n",
    "        test_df['assessmentItemID2idx'] = test_df['assessmentItemID'].apply(lambda x : assessmentItemID2idx[x])\n",
    "        test_df['testId2idx'] = test_df['testId'].apply(lambda x : testId2idx[x])\n",
    "        test_df['KnowledgeTag2idx'] = test_df['KnowledgeTag'].apply(lambda x : KnowledgeTag2idx[x])\n",
    "        test_df['problemNum2idx'] = test_df['problemNum'].apply(lambda x : problemNum2idx[x])\n",
    "        test_df['assessNum2idx'] = test_df['assessNum'].apply(lambda x : assessNum2idx[x])\n",
    "\n",
    "        self.assessmentItemID2idx = assessmentItemID2idx\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.train_test_df = pd.concat([train_df, test_df[test_df['answerCode'] != -1]]).reset_index(drop=True)\n",
    "        self.num_assessmentItemID = len(assessmentItemID2idx)\n",
    "        self.num_testId = len(testId2idx)\n",
    "        self.num_KnowledgeTag = len(KnowledgeTag2idx)\n",
    "        self.num_problemNum = len(problemNum2idx)\n",
    "        self.num_assessNum = len(assessNum2idx)\n",
    "        self.num_hour = 24\n",
    "        self.num_wday = 7\n",
    "        \n",
    "        print(\"train_shape\", train_df.shape)\n",
    "        print(\"test_shape\", test_df.shape)\n",
    "        print(\"train_test\", train_test_df.shape)\n",
    "\n",
    "    # train, valid 데이터 생성\n",
    "    def train_valid_split(self, kf):\n",
    "        val_users = self.user_data[kf]\n",
    "        train = []\n",
    "        valid = []\n",
    "\n",
    "        user_df = self.train_test_df.groupby('userID')\n",
    "\n",
    "        for userID, df in user_df:\n",
    "            if userID in val_users:\n",
    "                train_df_2 = df.iloc[:-1, :]\n",
    "                valid_df_2 = df.copy()\n",
    "                train.append(train_df_2)\n",
    "                valid.append(valid_df_2)\n",
    "            else:\n",
    "                train.append(df)\n",
    "\n",
    "        train = pd.concat(train).reset_index(drop = True)\n",
    "        valid = pd.concat(valid).reset_index(drop = True)\n",
    "        \n",
    "        print(\"train_shape\", train.shape)\n",
    "        print(\"validt_shape\", valid.shape)\n",
    "        \n",
    "        return train, valid\n",
    "    \n",
    "    # test 데이터 생성\n",
    "    def get_test_data(self):\n",
    "        print(\"test_shape\", self.test_df.shape)\n",
    "        return self.test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        cat_cols = ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', \n",
    "                    'assessNum2idx', 'hour', 'wday'],\n",
    "        num_cols = ['time'],\n",
    "        max_len = None,\n",
    "        window = None,\n",
    "        data_augmentation = False,\n",
    "        ):\n",
    "\n",
    "        self.cat_cols = cat_cols\n",
    "        self.num_cols = num_cols\n",
    "        self.get_df = df.groupby('userID')\n",
    "        self.user_list = df['userID'].unique().tolist()\n",
    "        self.max_len = max_len\n",
    "        self.window = window\n",
    "        self.data_augmentation = data_augmentation\n",
    "        if self.data_augmentation:\n",
    "            self.cat_feature_list, self.num_feature_list, self.answerCode_list = self._data_augmentation()\n",
    "\n",
    "        print(\"cat, num\", cat_cols, num_cols)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data_augmentation:\n",
    "            return len(self.cat_feature_list)\n",
    "        return len(self.user_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_augmentation:\n",
    "            cat_feature = self.cat_feature_list[idx]\n",
    "            num_feature = self.num_feature_list[idx]\n",
    "            answerCode = self.answerCode_list[idx]\n",
    "\n",
    "            now_cat_feature = cat_feature[1:, :]\n",
    "            now_num_feature = num_feature[1:, :]\n",
    "            now_answerCode = answerCode[1:]\n",
    "            \n",
    "            past_cat_feature = cat_feature[:-1, :]\n",
    "            past_num_feature = num_feature[:-1, :]\n",
    "            past_answerCode = answerCode[:-1]\n",
    "            \n",
    "        else:\n",
    "            user = self.user_list[idx]\n",
    "            if self.max_len:\n",
    "                get_df = self.get_df.get_group(user).iloc[-self.max_len:, :]\n",
    "            else:\n",
    "                get_df = self.get_df.get_group(user)\n",
    "\n",
    "            now_df = get_df.iloc[1:, :]\n",
    "            now_cat_feature = now_df[self.cat_cols].values\n",
    "            now_num_feature = now_df[self.num_cols].values\n",
    "            now_answerCode = now_df['answerCode'].values\n",
    "\n",
    "            past_df = get_df.iloc[:-1, :]\n",
    "            past_cat_feature = past_df[self.cat_cols].values\n",
    "            past_num_feature = past_df[self.num_cols].values\n",
    "            past_answerCode = past_df['answerCode'].values\n",
    "\n",
    "        return {\n",
    "            'past_cat_feature' : past_cat_feature, \n",
    "            'past_num_feature' : past_num_feature, \n",
    "            'past_answerCode' : past_answerCode, \n",
    "            'now_cat_feature' : now_cat_feature, \n",
    "            'now_num_feature' : now_num_feature, \n",
    "            'now_answerCode' : now_answerCode\n",
    "            }\n",
    "    \n",
    "\n",
    "    def _data_augmentation(self):\n",
    "        cat_feature_list = []\n",
    "        num_feature_list = []\n",
    "        answerCode_list = []\n",
    "        for userID, get_df in tqdm(self.get_df):\n",
    "            cat_feature = get_df[self.cat_cols].values[::-1]\n",
    "            num_feature = get_df[self.num_cols].values[::-1]\n",
    "            answerCode = get_df['answerCode'].values[::-1]\n",
    "\n",
    "            start_idx = 0\n",
    "\n",
    "            if len(get_df) <= self.max_len:\n",
    "                cat_feature_list.append(cat_feature[::-1])\n",
    "                num_feature_list.append(num_feature[::-1])\n",
    "                answerCode_list.append(answerCode[::-1])\n",
    "            else:\n",
    "                while True:\n",
    "                    if len(cat_feature[start_idx: start_idx + self.max_len, :]) < self.max_len:\n",
    "                        cat_feature_list.append(cat_feature[start_idx: start_idx + self.max_len, :][::-1])\n",
    "                        num_feature_list.append(num_feature[start_idx: start_idx + self.max_len, :][::-1])\n",
    "                        answerCode_list.append(answerCode[start_idx: start_idx + self.max_len][::-1])\n",
    "                        break\n",
    "                    cat_feature_list.append(cat_feature[start_idx: start_idx + self.max_len, :][::-1])\n",
    "                    num_feature_list.append(num_feature[start_idx: start_idx + self.max_len, :][::-1])\n",
    "                    answerCode_list.append(answerCode[start_idx: start_idx + self.max_len][::-1])\n",
    "                    start_idx += self.window\n",
    "            \n",
    "        return cat_feature_list, num_feature_list, answerCode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_len, padding_value = 0):\n",
    "    try:\n",
    "        seq_len, col = seq.shape\n",
    "        padding = np.zeros((max_len - seq_len, col)) + padding_value\n",
    "    except:\n",
    "        seq_len = seq.shape[0]\n",
    "        padding = np.zeros((max_len - seq_len, )) + padding_value\n",
    "\n",
    "    padding_seq = np.concatenate([padding, seq])\n",
    "\n",
    "    return padding_seq\n",
    "\n",
    "def train_make_batch(samples):\n",
    "    max_len = 0\n",
    "    for sample in samples:\n",
    "        seq_len, col = sample['past_cat_feature'].shape\n",
    "        if max_len < seq_len:\n",
    "            max_len = seq_len\n",
    "    \n",
    "    past_cat_feature = []\n",
    "    past_num_feature = []\n",
    "    past_answerCode = []\n",
    "    now_cat_feature = []\n",
    "    now_num_feature = []\n",
    "    now_answerCode = []\n",
    "\n",
    "    for sample in samples:\n",
    "        past_cat_feature += [pad_sequence(sample['past_cat_feature'] + 1, max_len = max_len, padding_value = 0)]\n",
    "        past_num_feature += [pad_sequence(sample['past_num_feature'], max_len = max_len, padding_value = 0)]\n",
    "        past_answerCode += [pad_sequence(sample['past_answerCode'] + 1, max_len = max_len, padding_value = 0)]\n",
    "        now_cat_feature += [pad_sequence(sample['now_cat_feature'] + 1, max_len = max_len, padding_value = 0)]\n",
    "        now_num_feature += [pad_sequence(sample['now_num_feature'], max_len = max_len, padding_value = 0)]\n",
    "        now_answerCode += [pad_sequence(sample['now_answerCode'], max_len = max_len, padding_value = -1)]\n",
    "\n",
    "    return torch.tensor(past_cat_feature, dtype = torch.long), torch.tensor(past_num_feature, dtype = torch.float32), torch.tensor(past_answerCode, dtype = torch.long), torch.tensor(now_cat_feature, dtype = torch.long), torch.tensor(now_num_feature, dtype = torch.float32), torch.tensor(now_answerCode, dtype = torch.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, model_dim, dropout_rate):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        Q, K, V : (batch_size, num_heads, max_len, model_dim)\n",
    "        attn_mask : (batch_size, 1, max_len, max_len)\n",
    "        \"\"\"\n",
    "        attn_score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self.model_dim) # (batch_size, num_heads, max_len, model_dim)\n",
    "        # 유사도가 0인 지점은 -infinity로 보내 softmax 결과가 0이 되도록 함\n",
    "        attn_score = attn_score.masked_fill(attn_mask == 0, -1e9)\n",
    "        attn_dist = self.dropout(F.softmax(attn_score, dim=-1))  # attention distribution\n",
    "        output = torch.matmul(attn_dist, V)  # (batch_size, num_heads, max_len, model_dim) / # dim of output : batchSize x num_head x seqLen x model_dim\n",
    "        \n",
    "        return output, attn_dist\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, model_dim, dropout_rate):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads # head의 수\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        # query, key, value, output 생성을 위해 Linear 모델 생성\n",
    "        self.W_Q = nn.Linear(model_dim, model_dim, bias=False)\n",
    "        self.W_K = nn.Linear(model_dim, model_dim, bias=False)\n",
    "        self.W_V = nn.Linear(model_dim, model_dim, bias=False)\n",
    "        self.W_O = nn.Linear(model_dim, model_dim, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(model_dim, dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate) # dropout rate\n",
    "        self.layerNorm = nn.LayerNorm(model_dim, 1e-6) # layer normalization\n",
    "\n",
    "    def forward(self, enc, attn_mask):\n",
    "        \"\"\"\n",
    "        enc : (batch_size, max_len, model_dim)\n",
    "        attn_mask : (batch_size, 1, max_len, max_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        residual = enc # residual connection을 위해 residual 부분을 저장\n",
    "        batch_size, seqlen = enc.size(0), enc.size(1)\n",
    "\n",
    "        # Query, Key, Value를 (num_head)개의 Head로 나누어 각기 다른 Linear projection을 통과시킴\n",
    "        Q = self.W_Q(enc).view(batch_size, seqlen, self.num_heads, self.model_dim // self.num_heads) # (batch_size, max_len, num_heads, model_dim)\n",
    "        K = self.W_K(enc).view(batch_size, seqlen, self.num_heads, self.model_dim // self.num_heads) # (batch_size, max_len, num_heads, model_dim)\n",
    "        V = self.W_V(enc).view(batch_size, seqlen, self.num_heads, self.model_dim // self.num_heads) # (batch_size, max_len, num_heads, model_dim)\n",
    "\n",
    "        # Head별로 각기 다른 attention이 가능하도록 Transpose 후 각각 attention에 통과시킴\n",
    "        Q, K, V = Q.transpose(1, 2), K.transpose(1, 2), V.transpose(1, 2) # (batch_size, num_heads, max_len, model_dim)\n",
    "        output, attn_dist = self.attention(Q, K, V, attn_mask) # output : (batch_size, num_heads, max_len, model_dim) / attn_dist : (batch_size, num_heads, max_len, max_len)\n",
    "\n",
    "        # 다시 Transpose한 후 모든 head들의 attention 결과를 합칩니다.\n",
    "        output = output.transpose(1, 2).contiguous() # (batch_size, max_len, num_heads, model_dim) / contiguous() : 가변적 메모리 할당\n",
    "        output = output.view(batch_size, seqlen, -1) # (batch_size, max_len, model_dim * num_heads)\n",
    "\n",
    "        # Linear Projection, Dropout, Residual sum, and Layer Normalization\n",
    "        output = self.layerNorm(self.dropout(self.W_O(output)) + residual) # (batch_size, max_len, model_dim)\n",
    "        return output, attn_dist\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, model_dim, dropout_rate):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.W_1 = nn.Linear(model_dim, model_dim)\n",
    "        self.W_2 = nn.Linear(model_dim, model_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layerNorm = nn.LayerNorm(model_dim, 1e-6) # layer normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        output = self.W_2(F.relu(self.dropout(self.W_1(x))))\n",
    "        output = self.layerNorm(self.dropout(output) + residual)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SASRecEncoder(nn.Module):\n",
    "    def __init__(self, num_heads, model_dim, dropout_rate):\n",
    "        super(SASRecEncoder, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, model_dim, dropout_rate)\n",
    "        self.pointwise_feedforward = PositionwiseFeedForward(model_dim, dropout_rate)\n",
    "\n",
    "    def forward(self, input_enc, attn_mask):\n",
    "        \"\"\"\n",
    "        input_enc : (batch_size, max_len, model_dim)\n",
    "        attn_mask : (batch_size, 1, max_len, max_len)\n",
    "        \"\"\"\n",
    "        output_enc, attn_dist = self.attention(input_enc, attn_mask)\n",
    "        output_enc = self.pointwise_feedforward(output_enc)\n",
    "        return output_enc, attn_dist\n",
    "\n",
    "\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_assessmentItemID, \n",
    "        num_testId,\n",
    "        num_KnowledgeTag,\n",
    "        num_problemNum,\n",
    "        num_assessNum,\n",
    "        num_hour,\n",
    "        num_wday,\n",
    "        num_cols,\n",
    "        cat_cols,\n",
    "        emb_size,\n",
    "        model_dim,\n",
    "        num_heads, \n",
    "        num_layers, \n",
    "        dropout_rate, \n",
    "        device):\n",
    "        super(SASRec, self).__init__()\n",
    "        \n",
    "        # 과거 정보\n",
    "        self.past_assessmentItemID_emb = nn.Embedding(num_assessmentItemID + 1, emb_size, padding_idx = 0)\n",
    "        self.past_testId_emb = nn.Embedding(num_testId + 1, emb_size, padding_idx = 0)\n",
    "        self.past_KnowledgeTag_emb = nn.Embedding(num_KnowledgeTag + 1, emb_size, padding_idx = 0)\n",
    "        self.past_problemNum_emb = nn.Embedding(num_problemNum + 1, emb_size, padding_idx = 0)\n",
    "        self.past_assessNum_emb = nn.Embedding(num_assessNum + 1, emb_size, padding_idx = 0)\n",
    "        self.past_hour_emb = nn.Embedding(num_hour + 1, emb_size, padding_idx = 0)\n",
    "        self.past_wday_emb = nn.Embedding(num_wday + 1, emb_size, padding_idx = 0)\n",
    "        \n",
    "        self.past_answerCode_emb = nn.Embedding(3, model_dim, padding_idx = 0)\n",
    "        self.past_cat_emb = nn.Sequential(\n",
    "            nn.Linear(len(cat_cols) * emb_size, model_dim // 2),\n",
    "            nn.LayerNorm(model_dim // 2, eps=1e-6)\n",
    "        )\n",
    "\n",
    "        self.past_num_emb = nn.Sequential(\n",
    "            nn.Linear(len(num_cols), model_dim // 2),\n",
    "            nn.LayerNorm(model_dim // 2, eps=1e-6)\n",
    "        )\n",
    "\n",
    "        self.emb_layernorm = nn.LayerNorm(model_dim, eps=1e-6)\n",
    "\n",
    "        self.past_lstm = nn.LSTM(\n",
    "            input_size = model_dim,\n",
    "            hidden_size = model_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            bidirectional = False,\n",
    "            dropout = dropout_rate,\n",
    "            )\n",
    "\n",
    "        self.past_blocks = nn.ModuleList([SASRecEncoder(num_heads, model_dim, dropout_rate) for _ in range(num_layers)])        \n",
    "        \n",
    "        # 현재 정보 - answerCode X\n",
    "        self.now_assessmentItemID_emb = nn.Embedding(num_assessmentItemID + 1, emb_size, padding_idx = 0)\n",
    "        self.now_testId_emb = nn.Embedding(num_testId + 1, emb_size, padding_idx = 0) \n",
    "        self.now_KnowledgeTag_emb = nn.Embedding(num_KnowledgeTag + 1, emb_size, padding_idx = 0) \n",
    "        self.now_problemNum_emb = nn.Embedding(num_problemNum + 1, emb_size, padding_idx = 0)\n",
    "        self.now_assessNum_emb = nn.Embedding(num_assessNum + 1, emb_size, padding_idx = 0)\n",
    "        self.now_hour_emb = nn.Embedding(num_hour + 1, emb_size, padding_idx = 0)\n",
    "        self.now_wday_emb = nn.Embedding(num_wday + 1, emb_size, padding_idx = 0) \n",
    "\n",
    "        self.now_cat_emb = nn.Sequential(\n",
    "            nn.Linear(len(cat_cols) * emb_size, model_dim // 2),\n",
    "            nn.LayerNorm(model_dim // 2, eps=1e-6)\n",
    "        )\n",
    "\n",
    "        self.now_num_emb = nn.Sequential(\n",
    "            nn.Linear(len(num_cols), model_dim // 2),\n",
    "            nn.LayerNorm(model_dim // 2, eps=1e-6)\n",
    "        )\n",
    "\n",
    "        self.now_lstm = nn.LSTM(\n",
    "            input_size = model_dim,\n",
    "            hidden_size = model_dim,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            bidirectional = False,\n",
    "            dropout = dropout_rate,\n",
    "            )\n",
    "\n",
    "        self.now_blocks = nn.ModuleList([SASRecEncoder(num_heads, model_dim, dropout_rate) for _ in range(num_layers)])\n",
    "\n",
    "        # predict\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.predict_layer = nn.Sequential(\n",
    "            nn.Linear(model_dim * 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.cat_cols = cat_cols\n",
    "        self.num_cols = num_cols\n",
    "        \n",
    "        self.model_dim = model_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "    \n",
    "    \n",
    "    def forward(self, past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature):\n",
    "        \"\"\"\n",
    "        past_cat_feature : (batch_size, max_len, cat_cols)\n",
    "        past_num_feature : (batch_size, max_len, num_cols)\n",
    "        past_answerCode : (batch_size, max_len)\n",
    "\n",
    "        now_cat_feature : (batch_size, max_len, cat_cols)\n",
    "        now_num_feature : (batch_size, max_len, num_cols)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        past_cat_emb_list = []\n",
    "        for idx in range(len(self.cat_cols)):\n",
    "            if self.cat_cols[idx] == 'assessmentItemID2idx':\n",
    "                past_cat_emb_list.append(self.past_assessmentItemID_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'testId2idx':\n",
    "                past_cat_emb_list.append(self.past_testId_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'KnowledgeTag2idx':\n",
    "                past_cat_emb_list.append(self.past_KnowledgeTag_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'problemNum2idx':\n",
    "                past_cat_emb_list.append(self.past_problemNum_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'assessNum2idx':\n",
    "                past_cat_emb_list.append(self.past_assessNum_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'hour':\n",
    "                past_cat_emb_list.append(self.past_hour_emb(past_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'wday':\n",
    "                past_cat_emb_list.append(self.past_wday_emb(past_cat_feature[:, :, idx]))\n",
    "\n",
    "        past_cat_emb = torch.concat(past_cat_emb_list, dim = -1)\n",
    "        past_cat_emb = self.past_cat_emb(past_cat_emb)\n",
    "        past_num_emb = self.past_num_emb(past_num_feature)\n",
    "\n",
    "        past_emb = torch.concat([past_cat_emb, past_num_emb], dim = -1)\n",
    "        past_emb += self.past_answerCode_emb(past_answerCode.to(self.device))\n",
    "        past_emb = self.emb_layernorm(past_emb) # LayerNorm\n",
    "\n",
    "        # attn_masking \n",
    "        attn_mask_pad = torch.BoolTensor(past_answerCode > 0).unsqueeze(1).unsqueeze(1) # (batch_size, 1, 1, max_len)\n",
    "        attn_mask_time = (1 - torch.triu(torch.ones((1, 1, past_answerCode.size(1), past_answerCode.size(1))), diagonal=1)).bool() # (batch_size, 1, max_len, max_len)\n",
    "        attn_mask = (attn_mask_pad & attn_mask_time).to(self.device) # (batch_size, 1, max_len, max_len)\n",
    "        for block in self.past_blocks:\n",
    "            past_emb, attn_dist = block(past_emb, attn_mask)\n",
    "\n",
    "        past_emb, _ = self.past_lstm(past_emb)\n",
    "\n",
    "        now_cat_emb_list = []\n",
    "        for idx in range(len(self.cat_cols)):\n",
    "            if self.cat_cols[idx] == 'assessmentItemID2idx':\n",
    "                now_cat_emb_list.append(self.now_assessmentItemID_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'testId2idx':\n",
    "                now_cat_emb_list.append(self.now_testId_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'KnowledgeTag2idx':\n",
    "                now_cat_emb_list.append(self.now_KnowledgeTag_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'problemNum2idx':\n",
    "                now_cat_emb_list.append(self.now_problemNum_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'assessNum2idx':\n",
    "                now_cat_emb_list.append(self.now_assessNum_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'hour':\n",
    "                now_cat_emb_list.append(self.now_hour_emb(now_cat_feature[:, :, idx]))\n",
    "            elif self.cat_cols[idx] == 'wday':\n",
    "                now_cat_emb_list.append(self.now_wday_emb(now_cat_feature[:, :, idx]))\n",
    "                \n",
    "        now_cat_emb = torch.concat(now_cat_emb_list, dim = -1)\n",
    "        now_cat_emb = self.now_cat_emb(now_cat_emb)\n",
    "        now_num_emb = self.now_num_emb(now_num_feature)\n",
    "\n",
    "        now_emb = torch.concat([now_cat_emb, now_num_emb], dim = -1)\n",
    "\n",
    "        for block in self.now_blocks:\n",
    "            now_emb, attn_dist = block(now_emb, attn_mask)\n",
    "\n",
    "        now_emb, _ = self.now_lstm(now_emb)\n",
    "\n",
    "        emb = torch.concat([past_emb, now_emb], dim = -1)\n",
    "        \n",
    "        output = self.predict_layer(self.dropout(emb))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "\n",
    "    for past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature, now_answerCode in data_loader:\n",
    "\n",
    "        past_cat_feature, past_num_feature, past_answerCode = past_cat_feature.to(device), past_num_feature.to(device), past_answerCode\n",
    "        now_cat_feature, now_num_feature, now_answerCode = now_cat_feature.to(device), now_num_feature.to(device), now_answerCode.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature).squeeze(2)\n",
    "        loss = criterion(output[now_answerCode != -1], now_answerCode[now_answerCode != -1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val += loss.item()\n",
    "\n",
    "    loss_val /= len(data_loader)\n",
    "\n",
    "    return loss_val\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    result = []\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature, now_answerCode in data_loader:\n",
    "            past_cat_feature, past_num_feature, past_answerCode = past_cat_feature.to(device), past_num_feature.to(device), past_answerCode\n",
    "            now_cat_feature, now_num_feature, now_answerCode = now_cat_feature.to(device), now_num_feature.to(device), now_answerCode.to(device)\n",
    "            \n",
    "            output = model(past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature).squeeze(2)\n",
    "\n",
    "            result.extend(now_answerCode[:, -1].cpu().numpy().tolist())\n",
    "            pred.extend(output[:, -1].cpu().numpy().tolist())\n",
    "\n",
    "    roc_auc = roc_auc_score(result, pred)\n",
    "    pred = np.array(pred)\n",
    "    acc_score = accuracy_score(result, np.where(pred >= 0.5, 1, 0))\n",
    "\n",
    "    return roc_auc, acc_score\n",
    "\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature, now_answerCode in data_loader:\n",
    "            past_cat_feature, past_num_feature, past_answerCode = past_cat_feature.to(device), past_num_feature.to(device), past_answerCode\n",
    "            now_cat_feature, now_num_feature = now_cat_feature.to(device), now_num_feature.to(device)\n",
    "            \n",
    "            output = model(past_cat_feature, past_num_feature, past_answerCode, now_cat_feature, now_num_feature).squeeze(2)\n",
    "            pred.extend(output[:, -1].cpu().numpy().tolist())\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "emb_size = 32\n",
    "model_dim = 128\n",
    "num_heads = 4 # 2,4,8,16,32\n",
    "num_layers = 1\n",
    "dropout_rate = 0.5\n",
    "num_workers = 4\n",
    "\n",
    "max_len = 50\n",
    "window = 10\n",
    "data_augmentation = False\n",
    "\n",
    "DATA_PATH = '/opt/ml/input/data'\n",
    "MODEL_PATH = '/opt/ml/input/notebooks/model'\n",
    "OUTPUT_PATH = '/opt/ml/input/notebooks/transformerlstm_output'\n",
    "\n",
    "model_name = 'baseline_10epoch.pt'\n",
    "result_file = 'baseline_10epochs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape (2266586, 16)\n",
      "test_shape (260114, 16)\n",
      "train_test (2525956, 9)\n"
     ]
    }
   ],
   "source": [
    "make_dataset = MakeDataset(DATA_PATH = DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape (2524467, 16)\n",
      "validt_shape (525799, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0th| Epoch:   1| Train loss: 0.49484| roc_auc: 0.82929| acc: 0.75084: 100%|██████████| 1/1 [01:31<00:00, 91.09s/it]\n",
      "0th| Epoch:   2| Train loss: 0.45305| roc_auc: 0.84047| acc: 0.76427: 100%|██████████| 1/1 [01:29<00:00, 89.51s/it]\n",
      "0th| Epoch:   3| Train loss: 0.44424| roc_auc: 0.84674| acc: 0.76293: 100%|██████████| 1/1 [01:32<00:00, 92.62s/it]\n",
      "0th| Epoch:   4| Train loss: 0.43935| roc_auc: 0.84819| acc: 0.77099: 100%|██████████| 1/1 [01:30<00:00, 90.98s/it]\n",
      "0th| Epoch:   5| Train loss: 0.43621| roc_auc: 0.85076| acc: 0.77032: 100%|██████████| 1/1 [01:29<00:00, 89.98s/it]\n",
      "0th| Epoch:   6| Train loss: 0.43343| roc_auc: 0.85206| acc: 0.77300: 100%|██████████| 1/1 [01:31<00:00, 91.49s/it]\n",
      "0th| Epoch:   7| Train loss: 0.43120| roc_auc: 0.85272| acc: 0.77770: 100%|██████████| 1/1 [01:30<00:00, 90.61s/it]\n",
      "0th| Epoch:   8| Train loss: 0.42846| roc_auc: 0.85180| acc: 0.77233: 100%|██████████| 1/1 [01:30<00:00, 90.81s/it]\n",
      "0th| Epoch:   9| Train loss: 0.42664| roc_auc: 0.85639| acc: 0.77569: 100%|██████████| 1/1 [01:30<00:00, 90.79s/it]\n",
      "0th| Epoch:  10| Train loss: 0.42536| roc_auc: 0.85677| acc: 0.77099: 100%|██████████| 1/1 [01:30<00:00, 90.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: 0| Epoch:  10| Train loss: 0.42536| roc_auc: 0.85677| acc: 0.77099\n",
      "train_shape (2524467, 16)\n",
      "validt_shape (517127, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1th| Epoch:   1| Train loss: 0.49262| roc_auc: 0.82239| acc: 0.75285: 100%|██████████| 1/1 [01:30<00:00, 90.54s/it]\n",
      "1th| Epoch:   2| Train loss: 0.45212| roc_auc: 0.82969| acc: 0.75151: 100%|██████████| 1/1 [01:31<00:00, 91.19s/it]\n",
      "1th| Epoch:   3| Train loss: 0.44392| roc_auc: 0.83450| acc: 0.75554: 100%|██████████| 1/1 [01:30<00:00, 90.38s/it]\n",
      "1th| Epoch:   4| Train loss: 0.43888| roc_auc: 0.83634| acc: 0.75823: 100%|██████████| 1/1 [01:30<00:00, 90.37s/it]\n",
      "1th| Epoch:   5| Train loss: 0.43601| roc_auc: 0.84319| acc: 0.76427: 100%|██████████| 1/1 [01:29<00:00, 89.58s/it]\n",
      "1th| Epoch:   6| Train loss: 0.43361| roc_auc: 0.84161| acc: 0.75554: 100%|██████████| 1/1 [01:30<00:00, 90.07s/it]\n",
      "1th| Epoch:   7| Train loss: 0.43127| roc_auc: 0.84268| acc: 0.76293: 100%|██████████| 1/1 [01:30<00:00, 90.19s/it]\n",
      "1th| Epoch:   8| Train loss: 0.42905| roc_auc: 0.84361| acc: 0.75957: 100%|██████████| 1/1 [01:29<00:00, 89.68s/it]\n",
      "1th| Epoch:   9| Train loss: 0.42723| roc_auc: 0.84508| acc: 0.75621: 100%|██████████| 1/1 [01:28<00:00, 88.99s/it]\n",
      "1th| Epoch:  10| Train loss: 0.42565| roc_auc: 0.84528| acc: 0.76427: 100%|██████████| 1/1 [01:28<00:00, 88.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: 1| Epoch:  10| Train loss: 0.42565| roc_auc: 0.84528| acc: 0.76427\n",
      "train_shape (2524468, 16)\n",
      "validt_shape (481022, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2th| Epoch:   1| Train loss: 0.49242| roc_auc: 0.82362| acc: 0.73723: 100%|██████████| 1/1 [01:29<00:00, 89.45s/it]\n",
      "2th| Epoch:   2| Train loss: 0.45236| roc_auc: 0.83007| acc: 0.75336: 100%|██████████| 1/1 [01:28<00:00, 88.31s/it]\n",
      "2th| Epoch:   3| Train loss: 0.44469| roc_auc: 0.83464| acc: 0.75739: 100%|██████████| 1/1 [01:28<00:00, 88.85s/it]\n",
      "2th| Epoch:   4| Train loss: 0.43946| roc_auc: 0.83563| acc: 0.75403: 100%|██████████| 1/1 [01:28<00:00, 88.87s/it]\n",
      "2th| Epoch:   5| Train loss: 0.43622| roc_auc: 0.83764| acc: 0.76075: 100%|██████████| 1/1 [01:26<00:00, 86.71s/it]\n",
      "2th| Epoch:   6| Train loss: 0.43422| roc_auc: 0.83937| acc: 0.75538: 100%|██████████| 1/1 [01:28<00:00, 88.98s/it]\n",
      "2th| Epoch:   7| Train loss: 0.43163| roc_auc: 0.84023| acc: 0.76008: 100%|██████████| 1/1 [01:28<00:00, 88.07s/it]\n",
      "2th| Epoch:   8| Train loss: 0.42954| roc_auc: 0.83846| acc: 0.75403: 100%|██████████| 1/1 [01:28<00:00, 88.75s/it]\n",
      "2th| Epoch:   9| Train loss: 0.42769| roc_auc: 0.84107| acc: 0.76344: 100%|██████████| 1/1 [01:28<00:00, 88.01s/it]\n",
      "2th| Epoch:  10| Train loss: 0.42545| roc_auc: 0.84007| acc: 0.75672: 100%|██████████| 1/1 [01:29<00:00, 89.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: 2| Epoch:   9| Train loss: 0.42769| roc_auc: 0.84107| acc: 0.76344\n",
      "train_shape (2524468, 16)\n",
      "validt_shape (514634, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3th| Epoch:   1| Train loss: 0.49406| roc_auc: 0.80749| acc: 0.73454: 100%|██████████| 1/1 [01:30<00:00, 90.11s/it]\n",
      "3th| Epoch:   2| Train loss: 0.45333| roc_auc: 0.81941| acc: 0.74261: 100%|██████████| 1/1 [01:29<00:00, 89.07s/it]\n",
      "3th| Epoch:   3| Train loss: 0.44396| roc_auc: 0.82526| acc: 0.75336: 100%|██████████| 1/1 [01:30<00:00, 90.68s/it]\n",
      "3th| Epoch:   4| Train loss: 0.43982| roc_auc: 0.82481| acc: 0.74798: 100%|██████████| 1/1 [01:29<00:00, 89.95s/it]\n",
      "3th| Epoch:   5| Train loss: 0.43626| roc_auc: 0.82905| acc: 0.74328: 100%|██████████| 1/1 [01:30<00:00, 90.51s/it]\n",
      "3th| Epoch:   6| Train loss: 0.43323| roc_auc: 0.83077| acc: 0.74866: 100%|██████████| 1/1 [01:29<00:00, 89.30s/it]\n",
      "3th| Epoch:   7| Train loss: 0.43134| roc_auc: 0.83041| acc: 0.75000: 100%|██████████| 1/1 [01:29<00:00, 89.30s/it]\n",
      "3th| Epoch:   8| Train loss: 0.42929| roc_auc: 0.83147| acc: 0.74798: 100%|██████████| 1/1 [01:28<00:00, 88.63s/it]\n",
      "3th| Epoch:   9| Train loss: 0.42751| roc_auc: 0.83366| acc: 0.76008: 100%|██████████| 1/1 [01:29<00:00, 89.11s/it]\n",
      "3th| Epoch:  10| Train loss: 0.42428| roc_auc: 0.83438| acc: 0.75269: 100%|██████████| 1/1 [01:28<00:00, 88.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: 3| Epoch:  10| Train loss: 0.42428| roc_auc: 0.83438| acc: 0.75269\n",
      "train_shape (2524468, 16)\n",
      "validt_shape (487374, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4th| Epoch:   1| Train loss: 0.49490| roc_auc: 0.81190| acc: 0.72379: 100%|██████████| 1/1 [01:29<00:00, 89.62s/it]\n",
      "4th| Epoch:   2| Train loss: 0.45291| roc_auc: 0.82580| acc: 0.75202: 100%|██████████| 1/1 [01:28<00:00, 88.10s/it]\n",
      "4th| Epoch:   3| Train loss: 0.44407| roc_auc: 0.82982| acc: 0.74664: 100%|██████████| 1/1 [01:29<00:00, 89.66s/it]\n",
      "4th| Epoch:   4| Train loss: 0.43926| roc_auc: 0.83457| acc: 0.75605: 100%|██████████| 1/1 [01:28<00:00, 88.22s/it]\n",
      "4th| Epoch:   5| Train loss: 0.43579| roc_auc: 0.83535| acc: 0.75470: 100%|██████████| 1/1 [01:29<00:00, 89.10s/it]\n",
      "4th| Epoch:   6| Train loss: 0.43281| roc_auc: 0.83376| acc: 0.75470: 100%|██████████| 1/1 [01:29<00:00, 89.88s/it]\n",
      "4th| Epoch:   7| Train loss: 0.43079| roc_auc: 0.83552| acc: 0.75739: 100%|██████████| 1/1 [01:28<00:00, 88.13s/it]\n",
      "4th| Epoch:   8| Train loss: 0.42900| roc_auc: 0.83783| acc: 0.75470: 100%|██████████| 1/1 [01:29<00:00, 89.57s/it]\n",
      "4th| Epoch:   9| Train loss: 0.42609| roc_auc: 0.84010| acc: 0.76008: 100%|██████████| 1/1 [01:29<00:00, 89.12s/it]\n",
      "4th| Epoch:  10| Train loss: 0.42522| roc_auc: 0.83582| acc: 0.75269: 100%|██████████| 1/1 [01:28<00:00, 88.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST: 4| Epoch:   9| Train loss: 0.42609| roc_auc: 0.84010| acc: 0.76008\n",
      "Total roc_auc: 0.84352\n",
      "Total accuracy: 0.76229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "roc_auc_sum = 0\n",
    "accuracy_sum = 0\n",
    "\n",
    "for kf in make_dataset.user_data.keys():\n",
    "    train_df, valid_df = make_dataset.train_valid_split(kf)\n",
    "    \n",
    "    train_dataset = CustomDataset(df = train_df,)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size = batch_size, \n",
    "        shuffle = True, \n",
    "        drop_last = False,\n",
    "        collate_fn = train_make_batch,\n",
    "        num_workers = num_workers)\n",
    "\n",
    "    valid_dataset = CustomDataset(df = valid_df,)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False, \n",
    "        drop_last = False,\n",
    "        collate_fn = train_make_batch,\n",
    "        num_workers = num_workers)\n",
    "\n",
    "    model = SASRec(\n",
    "        num_assessmentItemID = make_dataset.num_assessmentItemID, \n",
    "        num_testId = make_dataset.num_testId,\n",
    "        num_KnowledgeTag = make_dataset.num_KnowledgeTag,\n",
    "        num_problemNum = make_dataset.num_problemNum,\n",
    "        num_assessNum = make_dataset.num_assessNum,\n",
    "        num_hour = make_dataset.num_hour,\n",
    "        num_wday = make_dataset.num_wday,\n",
    "        num_cols = train_dataset.num_cols,\n",
    "        cat_cols = train_dataset.cat_cols,\n",
    "        emb_size = emb_size,\n",
    "        model_dim = model_dim,\n",
    "        num_heads = num_heads,\n",
    "        num_layers = num_layers,\n",
    "        dropout_rate = dropout_rate,\n",
    "        device = device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    best_epoch = 0\n",
    "    best_train_loss = 0\n",
    "    best_roc_auc = 0\n",
    "    best_acc_score = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        tbar = tqdm(range(1))\n",
    "        for _ in tbar:\n",
    "            train_loss = train(model = model, data_loader = train_data_loader, criterion = criterion, optimizer = optimizer)\n",
    "            roc_auc, acc_score = evaluate(model = model, data_loader = valid_data_loader)\n",
    "            if best_roc_auc < roc_auc:\n",
    "                best_epoch = epoch\n",
    "                best_train_loss = train_loss\n",
    "                best_roc_auc = roc_auc\n",
    "                best_acc_score = acc_score\n",
    "                torch.save(model.state_dict(), os.path.join(MODEL_PATH, f'kf_{kf}_' + model_name))\n",
    "\n",
    "            tbar.set_description(f'{kf}th| Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| roc_auc: {roc_auc:.5f}| acc: {acc_score:.5f}')\n",
    "    \n",
    "    print(f'BEST: {kf}| Epoch: {best_epoch:3d}| Train loss: {best_train_loss:.5f}| roc_auc: {best_roc_auc:.5f}| acc: {best_acc_score:.5f}')\n",
    "\n",
    "    roc_auc_sum += best_roc_auc\n",
    "    accuracy_sum += best_acc_score\n",
    "\n",
    "print(f'Total roc_auc: {roc_auc_sum / len(make_dataset.user_data.keys()):.5f}')\n",
    "print(f'Total accuracy: {accuracy_sum / len(make_dataset.user_data.keys()):.5f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_shape (260114, 16)\n",
      "cat, num ['assessmentItemID2idx', 'testId2idx', 'KnowledgeTag2idx', 'problemNum2idx', 'assessNum2idx', 'hour', 'wday'] ['time']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.64193972, 0.91323764, 0.22032824, 0.8416337 , 0.27325924,\n",
       "       0.92058537, 0.0485157 , 0.19747123, 0.2286058 , 0.97532802,\n",
       "       0.43776797, 0.49835216, 0.98377923, 0.26706039, 0.64891888,\n",
       "       0.97184798, 0.23315951, 0.84143393, 0.84900591, 0.17137689,\n",
       "       0.93230569, 0.7269426 , 0.55567912, 0.24137679, 0.15603156,\n",
       "       0.71061634, 0.98182261, 0.87030108, 0.60131362, 0.82556957,\n",
       "       0.80571358, 0.72673116, 0.8890286 , 0.24292438, 0.94778912,\n",
       "       0.93750449, 0.41539434, 0.64038433, 0.24150203, 0.20134338,\n",
       "       0.49991391, 0.22396898, 0.21820754, 0.37736266, 0.80851938,\n",
       "       0.95040762, 0.6694869 , 0.27754306, 0.98387988, 0.74261346,\n",
       "       0.75188448, 0.25698419, 0.32369766, 0.14725396, 0.38427038,\n",
       "       0.73809562, 0.31093937, 0.95270683, 0.03818707, 0.21899795,\n",
       "       0.92656964, 0.96015368, 0.86717758, 0.19608237, 0.08766978,\n",
       "       0.30105662, 0.72088877, 0.30522774, 0.24096195, 0.41791425,\n",
       "       0.71452502, 0.89663535, 0.02154435, 0.29433765, 0.19574808,\n",
       "       0.60599378, 0.2390009 , 0.72241744, 0.2606181 , 0.74895142,\n",
       "       0.2148753 , 0.65755137, 0.48505044, 0.61013461, 0.57656505,\n",
       "       0.26456335, 0.63714576, 0.23667468, 0.38509243, 0.27321822,\n",
       "       0.30533654, 0.0466095 , 0.28414336, 0.82987831, 0.82067305,\n",
       "       0.71471606, 0.0794949 , 0.76863288, 0.85295891, 0.93264773,\n",
       "       0.50995172, 0.24841439, 0.70879446, 0.10456775, 0.13617102,\n",
       "       0.778012  , 0.83792324, 0.94325227, 0.06364466, 0.44262086,\n",
       "       0.83938005, 0.96142886, 0.15191586, 0.24077832, 0.36186289,\n",
       "       0.85818813, 0.8652416 , 0.27610434, 0.77554318, 0.38709418,\n",
       "       0.80322715, 0.90924343, 0.96985382, 0.12423403, 0.00903583,\n",
       "       0.24283867, 0.81741488, 0.1593212 , 0.84244778, 0.07710187,\n",
       "       0.93053635, 0.19650733, 0.9589753 , 0.28633942, 0.86489003,\n",
       "       0.59437883, 0.23658677, 0.78945513, 0.51917334, 0.92699733,\n",
       "       0.81758051, 0.72197361, 0.23533781, 0.55145118, 0.77428912,\n",
       "       0.2411705 , 0.89809207, 0.93483618, 0.24241048, 0.70666279,\n",
       "       0.17429745, 0.76417434, 0.86554564, 0.04557572, 0.2051448 ,\n",
       "       0.47121553, 0.22341917, 0.3273147 , 0.57796819, 0.2811119 ,\n",
       "       0.68835082, 0.20494019, 0.42909487, 0.31873354, 0.73745918,\n",
       "       0.61870753, 0.06359447, 0.1208742 , 0.85006086, 0.50678419,\n",
       "       0.86200951, 0.33485923, 0.33267695, 0.04341195, 0.48442264,\n",
       "       0.95396163, 0.86059912, 0.02380977, 0.12176222, 0.28836911,\n",
       "       0.32398435, 0.18112461, 0.56411192, 0.191375  , 0.8815532 ,\n",
       "       0.8833347 , 0.69855551, 0.45256796, 0.94418911, 0.05034702,\n",
       "       0.41437773, 0.2200394 , 0.66797324, 0.98942448, 0.80020707,\n",
       "       0.64759458, 0.91186559, 0.86643555, 0.88242036, 0.19126549,\n",
       "       0.69038433, 0.56756328, 0.22118385, 0.51178421, 0.41936083,\n",
       "       0.90267755, 0.03027895, 0.1915739 , 0.40644466, 0.00274767,\n",
       "       0.31580242, 0.83821133, 0.1380704 , 0.52774911, 0.50616072,\n",
       "       0.43520742, 0.85957083, 0.73745482, 0.80388783, 0.80540898,\n",
       "       0.86608841, 0.6415392 , 0.26597866, 0.98205936, 0.90104352,\n",
       "       0.58905982, 0.7102491 , 0.04847127, 0.40906192, 0.19455206,\n",
       "       0.22266832, 0.56581187, 0.65752811, 0.70944449, 0.82732568,\n",
       "       0.86095293, 0.46877771, 0.23603589, 0.15585728, 0.74022683,\n",
       "       0.66621591, 0.38488287, 0.2719466 , 0.81998302, 0.86724899,\n",
       "       0.78569603, 0.2933679 , 0.90606718, 0.15908178, 0.17453003,\n",
       "       0.95555389, 0.85551863, 0.51456663, 0.79124391, 0.577309  ,\n",
       "       0.24783029, 0.81994457, 0.61948498, 0.08555631, 0.80005918,\n",
       "       0.00715894, 0.67989712, 0.00949107, 0.0520715 , 0.09384014,\n",
       "       0.07545066, 0.93637139, 0.94788516, 0.05321038, 0.01031272,\n",
       "       0.18022633, 0.22394389, 0.45043493, 0.78976068, 0.7252677 ,\n",
       "       0.08726232, 0.92283384, 0.07816254, 0.71107612, 0.96792192,\n",
       "       0.65197248, 0.75705028, 0.7769294 , 0.96785793, 0.3144805 ,\n",
       "       0.21473542, 0.24578997, 0.228247  , 0.7582182 , 0.72143192,\n",
       "       0.36521598, 0.29027506, 0.21126771, 0.01222514, 0.45991291,\n",
       "       0.41286129, 0.56663338, 0.72441764, 0.4886333 , 0.83756808,\n",
       "       0.74160703, 0.4042209 , 0.0785786 , 0.77581329, 0.67384183,\n",
       "       0.1129027 , 0.59352416, 0.94152424, 0.27092965, 0.85560706,\n",
       "       0.18727394, 0.02610983, 0.87177663, 0.22749584, 0.43163446,\n",
       "       0.83939056, 0.99010744, 0.356587  , 0.28788882, 0.7271582 ,\n",
       "       0.29709392, 0.63968425, 0.71199816, 0.09817968, 0.67389112,\n",
       "       0.25523055, 0.81819973, 0.07728126, 0.68429542, 0.78235905,\n",
       "       0.96917174, 0.07674002, 0.31563724, 0.36962313, 0.84909685,\n",
       "       0.64095235, 0.25963253, 0.62559093, 0.86664138, 0.68965545,\n",
       "       0.81853762, 0.60119706, 0.70247555, 0.21131337, 0.42943054,\n",
       "       0.94459025, 0.72132303, 0.19140801, 0.44155616, 0.77108597,\n",
       "       0.66391768, 0.35280609, 0.47765458, 0.84605632, 0.75706627,\n",
       "       0.73018663, 0.7853354 , 0.36733912, 0.53420136, 0.46210844,\n",
       "       0.60745687, 0.25284827, 0.20680342, 0.35399254, 0.37318597,\n",
       "       0.71035227, 0.78650666, 0.11195044, 0.08543764, 0.17908615,\n",
       "       0.38307477, 0.88627727, 0.84235657, 0.97132561, 0.2589847 ,\n",
       "       0.72753435, 0.71508921, 0.45745055, 0.81320934, 0.20842753,\n",
       "       0.22568252, 0.95397233, 0.78730439, 0.20689725, 0.48037232,\n",
       "       0.24624332, 0.2706512 , 0.73528925, 0.95209635, 0.90881337,\n",
       "       0.39517283, 0.04419901, 0.18901836, 0.15216748, 0.93051269,\n",
       "       0.0201577 , 0.84859196, 0.90783906, 0.14886507, 0.17723356,\n",
       "       0.83671857, 0.97412786, 0.68704689, 0.27402488, 0.22988966,\n",
       "       0.55812091, 0.88338907, 0.32180789, 0.24096717, 0.21824069,\n",
       "       0.47772107, 0.00112849, 0.4466391 , 0.63638085, 0.02145992,\n",
       "       0.49632608, 0.96224096, 0.74930713, 0.80708333, 0.62259566,\n",
       "       0.96255302, 0.69981747, 0.69849052, 0.53256353, 0.78847793,\n",
       "       0.08803828, 0.67827832, 0.3751417 , 0.78854085, 0.73034263,\n",
       "       0.82332813, 0.28040373, 0.9456206 , 0.90256155, 0.57862116,\n",
       "       0.76066614, 0.30963585, 0.2539437 , 0.83326793, 0.27708117,\n",
       "       0.28603466, 0.14365072, 0.22311104, 0.81306823, 0.14491048,\n",
       "       0.86721499, 0.12961804, 0.7936687 , 0.36033158, 0.26286616,\n",
       "       0.68533713, 0.72957253, 0.41340339, 0.29818153, 0.46132498,\n",
       "       0.33248122, 0.59340622, 0.71528956, 0.62228596, 0.30017817,\n",
       "       0.74349508, 0.91374652, 0.17865473, 0.69702091, 0.6710188 ,\n",
       "       0.67401079, 0.81748717, 0.07535007, 0.39391334, 0.7329087 ,\n",
       "       0.02579669, 0.1876589 , 0.8102849 , 0.92482141, 0.33657078,\n",
       "       0.61887442, 0.31546434, 0.27770508, 0.82151823, 0.81714563,\n",
       "       0.56124929, 0.63447109, 0.03574666, 0.24632949, 0.97544168,\n",
       "       0.19107286, 0.39153876, 0.01063054, 0.2161667 , 0.02924686,\n",
       "       0.02051311, 0.22035394, 0.5282671 , 0.24271615, 0.37878157,\n",
       "       0.04743112, 0.19726315, 0.44941016, 0.22303385, 0.79336826,\n",
       "       0.58065808, 0.63344014, 0.20052076, 0.27638863, 0.43790022,\n",
       "       0.58155864, 0.81035748, 0.84605036, 0.6243066 , 0.17792118,\n",
       "       0.66852808, 0.20904651, 0.80058861, 0.76992429, 0.58767378,\n",
       "       0.68507822, 0.95256515, 0.16968763, 0.52554381, 0.37195673,\n",
       "       0.82708342, 0.80124296, 0.82567928, 0.15891055, 0.92322242,\n",
       "       0.0239507 , 0.68679757, 0.34196378, 0.84125341, 0.3862056 ,\n",
       "       0.83813946, 0.11520297, 0.23469455, 0.79798975, 0.16601074,\n",
       "       0.38449481, 0.81599227, 0.52239947, 0.00930286, 0.58857464,\n",
       "       0.98287199, 0.88024437, 0.92483495, 0.37281372, 0.423801  ,\n",
       "       0.9504319 , 0.76704   , 0.87262262, 0.82206253, 0.68737397,\n",
       "       0.77227902, 0.36110179, 0.0907354 , 0.47181255, 0.24597626,\n",
       "       0.38428242, 0.58814024, 0.57818534, 0.84514825, 0.60217687,\n",
       "       0.69905559, 0.78073431, 0.64923707, 0.05723829, 0.21573715,\n",
       "       0.52825063, 0.01059961, 0.92329684, 0.21068484, 0.49582234,\n",
       "       0.19173749, 0.28149402, 0.00438294, 0.30141806, 0.29412233,\n",
       "       0.34444118, 0.20574703, 0.40112929, 0.6124073 , 0.79751695,\n",
       "       0.62413674, 0.89693418, 0.97788135, 0.09141236, 0.5687268 ,\n",
       "       0.32795821, 0.91042871, 0.30844697, 0.51162619, 0.63105162,\n",
       "       0.12621766, 0.85825793, 0.92200949, 0.69088824, 0.70204759,\n",
       "       0.31221189, 0.9557654 , 0.50409978, 0.09375704, 0.82084538,\n",
       "       0.87179714, 0.02014336, 0.83837095, 0.21038613, 0.85573908,\n",
       "       0.56199064, 0.3483271 , 0.85940504, 0.24458422, 0.84763083,\n",
       "       0.26573109, 0.38541167, 0.98711523, 0.0121504 , 0.26918477,\n",
       "       0.86660771, 0.97138095, 0.04870619, 0.34256924, 0.06025123,\n",
       "       0.26649975, 0.05139134, 0.03111578, 0.07351045, 0.12396552,\n",
       "       0.00478389, 0.20656514, 0.80793173, 0.16347416, 0.8089843 ,\n",
       "       0.10207968, 0.48383822, 0.60114512, 0.56346798, 0.67602168,\n",
       "       0.02125721, 0.8110296 , 0.22864565, 0.67611252, 0.64143915,\n",
       "       0.60761958, 0.52368565, 0.03492718, 0.34924423, 0.18076599,\n",
       "       0.23937964, 0.17774001, 0.79289688, 0.30804305, 0.44928328,\n",
       "       0.05414599, 0.73277673, 0.91049126, 0.87451653, 0.01960685,\n",
       "       0.38920533, 0.24378152, 0.96163554, 0.50831339, 0.18315618,\n",
       "       0.06487011, 0.75414646, 0.61818347, 0.24483077, 0.82879779,\n",
       "       0.56120807, 0.60278152, 0.57406883, 0.5987426 , 0.5590697 ,\n",
       "       0.52009407, 0.0012796 , 0.92016176, 0.30117093, 0.13481565,\n",
       "       0.96199915, 0.01108543, 0.91917917, 0.33202519, 0.24037323,\n",
       "       0.38237784, 0.60422628, 0.71243345, 0.75021653, 0.64317842,\n",
       "       0.65236505, 0.53115472, 0.64582592, 0.87997798, 0.68087522,\n",
       "       0.7696618 , 0.62021951, 0.60218883, 0.76207513, 0.76346086,\n",
       "       0.07811262, 0.24166621, 0.00285003, 0.11331396, 0.73769419,\n",
       "       0.42406127, 0.91815794, 0.86605704, 0.61367507, 0.05741971,\n",
       "       0.00577924, 0.00662523, 0.60826718, 0.05726783, 0.05939308,\n",
       "       0.79511675, 0.48600931, 0.85316157, 0.28411574, 0.00256897,\n",
       "       0.80238074, 0.89818456, 0.38901413, 0.57499143, 0.60868134,\n",
       "       0.39158328, 0.59428731, 0.11041389, 0.80730572, 0.68030207,\n",
       "       0.78845366, 0.15008196, 0.02259615, 0.7238077 , 0.05650436,\n",
       "       0.88208108, 0.35030002, 0.66575011, 0.52615477, 0.44253131,\n",
       "       0.56653793, 0.89185547, 0.25142992, 0.56134456, 0.00392903,\n",
       "       0.84518218, 0.88558708, 0.8803977 , 0.38011563])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = make_dataset.get_test_data()\n",
    "test_dataset = CustomDataset(df = test_df)\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 1, \n",
    "    shuffle = False, \n",
    "    drop_last = False,\n",
    "    collate_fn = train_make_batch,\n",
    "    num_workers = num_workers)\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "model = SASRec(\n",
    "    num_assessmentItemID = make_dataset.num_assessmentItemID, \n",
    "    num_testId = make_dataset.num_testId,\n",
    "    num_KnowledgeTag = make_dataset.num_KnowledgeTag,\n",
    "    num_problemNum = make_dataset.num_problemNum,\n",
    "    num_assessNum = make_dataset.num_assessNum,\n",
    "    num_hour = make_dataset.num_hour,\n",
    "    num_wday = make_dataset.num_wday,\n",
    "    num_cols = train_dataset.num_cols,\n",
    "    cat_cols = train_dataset.cat_cols,\n",
    "    emb_size = emb_size, \n",
    "    model_dim = model_dim, \n",
    "    num_heads = num_heads, \n",
    "    num_layers = num_layers, \n",
    "    dropout_rate = dropout_rate, \n",
    "    device = device).to(device)\n",
    "\n",
    "for kf in make_dataset.user_data.keys():\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_PATH, f'kf_{kf}_' + model_name)))\n",
    "    pred = predict(model = model, data_loader = test_data_loader)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "pred_list = np.array(pred_list).mean(axis = 0)\n",
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data = np.array(pred_list), columns = ['prediction'])\n",
    "submission['id'] = submission.index\n",
    "submission = submission[['id', 'prediction']]\n",
    "submission.to_csv(os.path.join(OUTPUT_PATH, 'trans_lstm_10epoch' + result_file), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.641940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.913238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.220328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.841634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>739</td>\n",
       "      <td>0.003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>0.845182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>0.885587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>0.880398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743</td>\n",
       "      <td>0.380116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  prediction\n",
       "0      0    0.641940\n",
       "1      1    0.913238\n",
       "2      2    0.220328\n",
       "3      3    0.841634\n",
       "4      4    0.273259\n",
       "..   ...         ...\n",
       "739  739    0.003929\n",
       "740  740    0.845182\n",
       "741  741    0.885587\n",
       "742  742    0.880398\n",
       "743  743    0.380116\n",
       "\n",
       "[744 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  prediction\n",
       "0   0           1\n",
       "1   1           1\n",
       "2   2           0\n",
       "3   3           1\n",
       "4   4           0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = submission.copy()\n",
    "df2['prediction'] = df2['prediction'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "labels = df2['prediction'].unique()\n",
    "ratio = df2[['prediction']].value_counts()\n",
    "colors = sns.color_palette('pastel')[0:2]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "plt.pie(ratio, labels=labels, autopct='%.1f%%', shadow=True, colors=colors, \n",
    "        textprops={'fontsize': 12})\n",
    "plt.title('prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
